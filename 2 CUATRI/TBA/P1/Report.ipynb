{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Universidad de Alicante </center>\n",
    "<p align=\"center\"><img src=\".ipynb_gfx/UA.png\" width=\"330\" height=\"190\"></p>\n",
    "<br>\n",
    "\n",
    "**Nombre:** Santiago Álvarez Geanta <br>\n",
    "**Fecha:** 7 de febrero de 2025 <br>\n",
    "**Grado:** Ingeniería en Inteligencia Artificial <br>\n",
    "**Grupo:** 1 <br>\n",
    "\n",
    "\n",
    "### Profesores\n",
    "- Francisco Escolano Ruíz\n",
    "- Ahmed Begga Hachlafi\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis comparativo\n",
    "\n",
    "## Primera parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar la efectividad del matching de keypoints entre imágenes, hemos calculado precisión para cada categoría de imagen utilizando:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{accuracy} = \\frac{\\text{Number of correctly matched keypoints}}{\\text{Total number of keypoints}}\n",
    "$$\n",
    "\n",
    "Realizamos este cálculo para todas las imágenes dentro de cada una de las cinco categorías, para así obtener el `accuracy` en diferentes contextos. Además, por cada `accuracy` de cada categoría hemos obtenido la media y la desviación utilizando las funciónes de numpy **np.mean()** y **np.std()**:\n",
    "\n",
    "* Mean Accuracy: Representa la precisión promedio alcanzada por el algoritmo en todas las imágenes de la categoría.\n",
    "* std Deviation: Mide la variabilidad de las precisiones obtenidas entre todas las imágenes de la categoría\n",
    "\n",
    "También he utilizado un archivo.csv llamado `results2.csv` para almacenar los resultados de cada categoría. \n",
    "\n",
    "| Categoría   | Mean Accuracy    | Std Deviation | Número de Imágenes |\n",
    "|-------------|------------------|---------------------|--------------------|\n",
    "| Duck        | 0.8250           | 0.2203              | 13                 |\n",
    "| Car         | 0.9500           | 0.0866              | 13                 |\n",
    "| Face        | 1.0              | 0.0                 | 13                 |\n",
    "| Motorbike   | 0.9667           | 0.0744              | 13                 |\n",
    "| Winebottle  | 0.8667           | 0.1700              | 13                 |\n",
    "\n",
    "\n",
    "### Análisis de Resultados:\n",
    "\n",
    "* Mean Accuracy: A primera vista podemos ver como la categoría `Face` alcanzó una precisión perfecta de 1.0, lo que indica que el algoritmo emparejó todos los keypoints correctamente en estas imágenes. Otras categorías, como `Car` y `Motorbike`, también lograron altas precisiones, cercanas al 95-97%, lo que indica que el algoritmo fue muy efectivo en la mayoría de los casos.\n",
    "\n",
    "* Std Deviation: La desviación estándar más baja obtenida se observa en `Face` y `Motorbike` (≈ 0.0). Por otro lado, categorías como `Duck` y `Winebottle` han mostrado una mayor dispersión.\n",
    "\n",
    "* Número de Imágenes Procesadas: Cada categoría tuvo un total de 13 imágenes procesada. Tomamos una imagen fija que fue comparada junto con otras 12 para así lograr formar 13 pares de comparaciones.\n",
    "\n",
    "El análisis y los resultados obtenidos muestran que el algoritmo de matching utilizando **distintas métricas de distancia** es bastante preciso y consistente, con algunas variaciones dependiendo de la categoría de imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda parte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos muestran diferencias significativas en la precisión del matching entre las distintas categorías. En la primera evaluación, las categorías Face y Motorbike tienen una precisión perfecta de 1.0 con una desviación estándar de 0.0. La categoría Winebottle también obtuvo una precisión muy alta (0.9833) con una baja variabilidad (0.0553), lo que sugiere una consistencia en los resultados. Car y Duck tienen una precisión ligeramente inferior, con valores de 0.9667 y 0.9167 respectivamente, aunque con mayores desviaciones estándar, especialmente en el caso de Duck (0.1908), lo que indica mayor variabilidad en los resultados.\n",
    "\n",
    "En contraste, la segunda evaluación muestra una disminución general en la precisión media de todas las categorías. Winebottle sigue siendo la categoría con mejor desempeño (0.8826), aunque con una desviación estándar mayor (0.1792). Face y Motorbike también obtienen valores elevados (0.8350 y 0.8265), pero con mayor variabilidad que en la primera evaluación. Car y Duck experimentan una reducción notable en la precisión media, alcanzando 0.7118 y 0.6753 respectivamente, con desviaciones estándar más altas (0.3007 y 0.2878), lo que indica una mayor dispersión en los resultados.\n",
    "\n",
    "En conclusión al incluir features tales como Node2Vec y Hitting Time, el matching se vuelve más robusto y preciso, especialmente en categorías con estructuras más complejas, como Face y Motorbike, que lograron una precisión perfecta (1.0) y una desviación estándar mínima.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>Spatial Only </td>\n",
    "        <td>Features</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"Delaunay(spatialonly).png\" width=\"700\"/></td>\n",
    "        <td><img src=\"Delaunay(features).png\" width=\"700\"/></td>\n",
    "    </tr>\n",
    "    \n",
    "        \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método KNN clasifica imágenes basándose en la similitud con sus k vecinos más cercanos. Al realizar las distintas comparaciones de KNN con 3, 5 y 7 vecinos, vemos como el resultado obtenido en cada una de ellas varía.\n",
    "\n",
    "* KNN(3) : Más sensible a ruido y valores atípicos, sería recomendable usarlo para detectar detalles finos.\n",
    "\n",
    "* KNN(5): De las comparaciones realizadas con el algoritmo KNN esta sería cosniderada la más equilibrada y menos afectado por ruido en los datos.\n",
    "    \n",
    "* KNN(7): Al utilizar tanta información sobre los vecinos obtenemos mayor estabilidad, pero menor sensibilidad a pequeños patrones.\n",
    "\n",
    "Respecto a la Triangulación de Delaunay podemos definirlo como un método geométrico que divide el espacio en triángulos conectados a partir de los keypoints, para la clasificación de formas.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <tr>\n",
    "        <td><img src=\"Duck_Delaunay.png\" width=\"700\"/></td>\n",
    "        <td><img src=\"Duck_KNN3.png\" width=\"700\"/></td>\n",
    "    </tr>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><img src=\"Duck_KNN5.png\" width=\"700\"/></td>\n",
    "        <td><img src=\"Duck_KNN7.png\" width=\"700\"/></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Por tanto, podemos concluir que la Triangulación de Delaunay puede proporcionar mejores resultados en términos de forma. Pero si lo que buscas es flexibilidad KNN es más adecuado ya que Delaunay depende de la disposición de los puntos clave en la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando matching KNN vs Delaunay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se comparan los resultados obtenidos mediante el algoritmo de K-Nearest Neighbors (KNN) y la Triangulación de Delaunay para diferentes valores de k en el conjunto de datos Car. Los resultados de precisión media y desviación estándar para distintos valores de k fueron los siguientes.\n",
    "\n",
    "\n",
    "| K  | Mean Accuracy          | Std Deviation          |\n",
    "|----|------------------------|------------------------|\n",
    "| 3  | 0.7363636363636363     | 0.24595907742670334    |\n",
    "| 5  | 0.9818181818181819     | 0.05749595745760689    |\n",
    "| 7  | 1.0                    | 0.0                    |\n",
    "| -  | 0.9454545454545454     | 0.12331509060227759    |\n",
    "\n",
    "\n",
    "* Para **k = 3**: La precisión media es de aproximadamente 0.736 con una desviación estándar bastante alta (0.246), lo que indica que el modelo tiene una variabilidad significativa en sus predicciones. Esto se debe a que con un valor bajo de k, el modelo es más sensible a las fluctuaciones en los datos de entrenamiento ya que no tiene tanta información.\n",
    "\n",
    "* Para **k = 5**: La precisión mejora significativamente a 0.982 y la desviación estándar disminuye a 0.0575, lo que sugiere que el modelo es más estable y preciso cuando se utilizan más vecinos.\n",
    "\n",
    "* Para **k = 7**: Se alcanza una precisión perfecta de 1.0 con una desviación estándar de 0.0, lo que indica que el modelo predice sin errores para este valor de k.\n",
    "\n",
    "* **Delaunay**: Para la triangulación de Delaunay, se obtiene una precisión media de 0.945 con una desviación estándar de 0.123. Se muestra un buen rendimiento general, pero con algo más de variabilidad en las predicciones en comparación con el modelo KNN con k = 7. La triangulación de Delaunay, en este caso, puede ser menos precisa en términos de clasificación, ya que no tiene en cuenta las distancias a los vecinos más cercanos de la misma manera que el KNN.\n",
    "\n",
    "\n",
    "Conclusión\n",
    "A medida que el número de vecinos aumenta (con k = 5 y k = 7), el modelo de KNN muestra una mejora significativa en la precisión y estabilidad. En comparación, la triangulación de Delaunay puede proporcionar una estructura más robusta, aunque en términos de precisión para clasificación, KNN parece más flexible y efectivo en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis respecto a los pesos utilizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Peso                          | Mean Accuracy | Std Deviation |\n",
    "|-------------------------------|---------------|---------------|\n",
    "| [0.3, 0.35, 0.35]              | 0.9091        | 0.1311        |\n",
    "| [0.4, 0.3, 0.3]                | 0.9364        | 0.1494        |\n",
    "| [0.5, 0.25, 0.25]              | 0.9818        | 0.0575        |\n",
    "| [0.6, 0.2, 0.2]                | 0.9182        | 0.1113        |\n",
    "| [0.4, 0.2, 0.4]                | 0.9636        | 0.0771        |\n",
    "| [0.35, 0.3, 0.35]              | 0.9818        | 0.0575        |\n",
    "| [0.3, 0.4, 0.3]                | 0.9636        | 0.0771        |\n",
    "| [0.4, 0.4, 0.2]                | 0.9000        | 0.1128        |\n",
    "| [0.35, 0.35, 0.3]              | 0.8909        | 0.1311        |\n",
    "| [0.3, 0.3, 0.4]                | 0.9273        | 0.0962        |\n",
    "\n",
    "\n",
    "En base a los resultados obtenidos con las diferentes configuraciones de pesos para las distancias de hitting time, node2vec y Euclidean (espacial), hemos llegado al siguiente análisis general sobre cuál es la combinación de pesos que mejor contribuye a la precisión.\n",
    "\n",
    "\n",
    "* **Mayor Precisión con el Equilibrio entre las Tres Métricas:** Las configuraciones con una distribución equitativa entre los tres componentes, como el caso de [0.35, 0.3, 0.35], muestran un alto rendimiento en términos de precisión media (alrededor del 98%), con una baja desviación estándar. Esto sugiere que un balance entre las tres métricas es más efectivo para lograr una buena precisión sin que ninguna métrica tenga un dominio demasiado fuerte, lo que indica una gran **estabilidad** general del modelo.\n",
    "\n",
    "* **Peso Mayor en Distancia Espacial:** Configuraciones como [0.6, 0.2, 0.2] muestran una ligera disminución en la precisión media (alrededor del 91.8%) y una desviación estándar relativamente baja. Esto indica que darle mayor importancia a la distancia Euclidiana no es la mejor estrategia. Aunque la precisión sigue siendo alta, esta configuración puede no aprovechar completamente la capacidad de los otros dos componentes, como node2vec y hitting time, más relevantes en este contexto.\n",
    "\n",
    "* **Mayor Peso en Node2Vec o Hitting Time:** En algunos casos, las configuraciones que asignan un peso más alto a node2vec o hitting time, como [0.4, 0.3, 0.3], ofrecen resultados intermedios en cuanto a precisión (alrededor del 93.6%), pero con mayor variabilidad en los resultados (mayor desviación estándar). Esta variabilidad refleja una tendencia a confiar más en las relaciones estructurales de los puntos. \n",
    "\n",
    "Conclusión:\n",
    "Los resultados sugieren que las configuraciones con pesos equilibrados entre las tres distancias (como [0.5, 0.25, 0.25] o [0.35, 0.3, 0.35]) tienden a ofrecer el mejor rendimiento en términos de precisión y estabilidad. Un peso ligeramente mayor en la distancia Euclidiana también puede ser beneficioso en términos generales. En cambio, si tenemos clara la estructura de nuestros puntos, un mayor peso en las métricas de Node2Vec e Hitting Time pueden ser beneficioso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Santiago Álvarez Geanta</center>\n",
    "#### <center>Universidad de Alicante</center>\n",
    "<p align=\"center\"><img src=\".ipynb_gfx/UA.png\" width=\"165\" height=\"95\"></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
